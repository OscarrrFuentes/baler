{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot # for reading .root files\n",
    "import pandas as pd # to store data as dataframe\n",
    "import time # to measure time to analyse\n",
    "import math # for mathematical functions such as square root\n",
    "import numpy as np # # for numerical calculations such as histogramming\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "from matplotlib.ticker import MaxNLocator,AutoMinorLocator # for minor ticks\n",
    "from lmfit.models import PolynomialModel, GaussianModel # for the signal and background fits\n",
    "import requests # for HTTP access\n",
    "import aiohttp # HTTP client support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lumi = 0.5 # fb-1 # data_A only\n",
    "#lumi = 1.9 # fb-1 # data_B only\n",
    "#lumi = 2.9 # fb-1 # data_C only\n",
    "#lumi = 4.7 # fb-1 # data_D only\n",
    "lumi = 10 # fb-1 # data_A,data_B,data_C,data_D\n",
    "\n",
    "fraction = 1 # reduce this is you want the code to run quicker\n",
    "\n",
    "#tuple_path = \"Input/GamGam/Data/\" # local \n",
    "tuple_path = \"https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/GamGam/Data/\" # web address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_list = ['data_A','data_B','data_C','data_D'] # add if you want more data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_files():\n",
    "\n",
    "    frames = [] # define empty list to hold data\n",
    "    for val in samples_list: # loop over each file\n",
    "        fileString = tuple_path+val+\".GamGam.root\" # file name to open\n",
    "        temp = read_file(fileString,val) # call the function read_file defined below\n",
    "        frames.append(temp) # append dataframe returned from read_file to list of dataframes\n",
    "    data = pd.concat(frames) # concatenate list of dataframes together into one dataframe\n",
    "    \n",
    "    return data # return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_myy(photon_pt,photon_eta,photon_phi,photon_E):\n",
    "    # first photon is [0], 2nd photon is [1] etc\n",
    "    px_0 = photon_pt[0]*math.cos(photon_phi[0]) # x-component of photon[0] momentum\n",
    "    py_0 = photon_pt[0]*math.sin(photon_phi[0]) # y-component of photon[0] momentum\n",
    "    pz_0 = photon_pt[0]*math.sinh(photon_eta[0]) # z-component of photon[0] momentum\n",
    "    px_1 = photon_pt[1]*math.cos(photon_phi[1]) # x-component of photon[1] momentum\n",
    "    py_1 = photon_pt[1]*math.sin(photon_phi[1]) # y-component of photon[1] momentum\n",
    "    pz_1 = photon_pt[1]*math.sinh(photon_eta[1]) # z-component of photon[1] momentum\n",
    "    sumpx = px_0 + px_1 # x-component of diphoton momentum\n",
    "    sumpy = py_0 + py_1 # y-component of diphoton momentum\n",
    "    sumpz = pz_0 + pz_1 # z-component of diphoton momentum \n",
    "    sump = math.sqrt(sumpx**2 + sumpy**2 + sumpz**2) # magnitude of diphoton momentum \n",
    "    sumE = photon_E[0] + photon_E[1] # energy of diphoton system\n",
    "    return math.sqrt(sumE**2 - sump**2)/1000 #/1000 to go from MeV to GeV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut on photon reconstruction quality\n",
    "# paper: \"Photon candidates are required to pass identification criteria\"\n",
    "def cut_photon_reconstruction(photon_isTightID):\n",
    "# isTightID==True means a photon identified as being well reconstructed\n",
    "# want to keep events where True for both photons\n",
    "# first photon is [0], 2nd photon is [1] etc\n",
    "    return photon_isTightID[0]==True and photon_isTightID[1]==True\n",
    "    \n",
    "# Cut on Transverse momentum\n",
    "# paper: \"The leading (sub-leading) photon candidate is required to have ET > 40 GeV (30 GeV)\"\n",
    "def cut_photon_pt(photon_pt):\n",
    "# want to keep events where photon_pt[0]>40000 MeV and photon_pt[1]>30000 MeV\n",
    "    return photon_pt[0]>40000 and photon_pt[1]>30000\n",
    "\n",
    "# Cut on energy isolation\n",
    "# paper: \"Photon candidates are required to have an isolation transverse energy of less than 4 GeV\"\n",
    "def cut_isolation_et(photon_etcone20):\n",
    "# want to keep events where isolation eT<4000 MeV\n",
    "    return photon_etcone20[0]<4000 and photon_etcone20[1]<4000\n",
    "\n",
    "# Cut on pseudorapidity in barrel/end-cap transition region\n",
    "# paper: \"excluding the calorimeter barrel/end-cap transition region 1.37 < |Î·| < 1.52\"\n",
    "def cut_photon_eta_transition(photon_eta):\n",
    "# want to keep events where modulus of photon_eta is outside the range 1.37 to 1.52\n",
    "    return (abs(photon_eta[0])>1.52 or abs(photon_eta[0])<1.37) and (abs(photon_eta[1])>1.52 or abs(photon_eta[1])<1.37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path,sample):\n",
    "    start = time.time() # start the clock\n",
    "    print(\"Processing: \"+sample) # print which sample is being processed\n",
    "    data_all = pd.DataFrame() # define empty pandas DataFrame to hold all data for this sample\n",
    "    tree = uproot.open(path + \":mini\")\n",
    "    numevents = tree.num_entries # number of events\n",
    "    for data in tree.iterate([\"photon_pt\",\"photon_eta\",\"photon_phi\",\"photon_E\",\n",
    "                            \"photon_isTightID\",\"photon_etcone20\"], # add more variables here if you want to use them\n",
    "                           library=\"pd\", # choose output type as pandas DataFrame\n",
    "                           entry_stop=numevents*fraction): # process up to numevents*fraction\n",
    "\n",
    "        nIn = len(data.index) # number of events in this batch\n",
    "        \n",
    "        # Cut on photon reconstruction quality using the function cut_photon_reconstruction defined above\n",
    "        data = data[ np.vectorize(cut_photon_reconstruction)(data.photon_isTightID)]\n",
    "        \n",
    "        # Cut on transverse momentum of the photons using the function cut_photon_pt defined above\n",
    "        data = data[ np.vectorize(cut_photon_pt)(data.photon_pt)]\n",
    "        \n",
    "        # Cut on energy isolation using the function cut_isolation_et defined above\n",
    "        data = data[ np.vectorize(cut_isolation_et)(data.photon_etcone20)]\n",
    "        \n",
    "        # Cut on pseudorapidity inside barrel/end-cap transition region using the function cut_photon_eta_transition\n",
    "        data = data[ np.vectorize(cut_photon_eta_transition)(data.photon_eta)]\n",
    "        \n",
    "        # Calculate reconstructed diphoton invariant mass using the function calc_myy defined above\n",
    "        data['myy'] = np.vectorize(calc_myy)(data.photon_pt,data.photon_eta,data.photon_phi,data.photon_E)\n",
    "        \n",
    "        # dataframe contents can be printed at any stage like this\n",
    "        #print(data)\n",
    "\n",
    "        # dataframe column can be printed at any stage like this\n",
    "        #print(data['photon_pt'])\n",
    "\n",
    "        # multiple dataframe columns can be printed at any stage like this\n",
    "        #print(data[['photon_pt','photon_eta']])\n",
    "\n",
    "        nOut = len(data.index) # number of events passing cuts in this batch\n",
    "        data_all = pd.concat([data_all, data], ignore_index=True)\n",
    "        elapsed = time.time() - start # time taken to process\n",
    "        print(\"\\t nIn: \"+str(nIn)+\",\\t nOut: \\t\"+str(nOut)+\"\\t in \"+str(round(elapsed,1))+\"s\") # events before and after\n",
    "    \n",
    "    return data_all # return dataframe containing events passing all cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: data_A\n",
      "\t nIn: 430344,\t nOut: \t22350\t in 5.4s\n",
      "Processing: data_B\n",
      "\t nIn: 1528717,\t nOut: \t77574\t in 11.4s\n",
      "Processing: data_C\n",
      "\t nIn: 1991156,\t nOut: \t101273\t in 18.3s\n",
      "\t nIn: 246031,\t nOut: \t12824\t in 84.4s\n",
      "Processing: data_D\n",
      "\t nIn: 1912410,\t nOut: \t96464\t in 21.4s\n",
      "\t nIn: 1689766,\t nOut: \t87478\t in 133.1s\n",
      "Time taken: 426.1s\n"
     ]
    }
   ],
   "source": [
    "start = time.time() # time at start of whole processing\n",
    "data = get_data_from_files() # process all files\n",
    "elapsed = time.time() - start # time after whole processing\n",
    "print(\"Time taken: \"+str(round(elapsed,1))+\"s\") # print total time taken to process every file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data):   \n",
    "\n",
    "    xmin = 100 # GeV\n",
    "    xmax = 160 # GeV\n",
    "    step_size = 3 # GeV\n",
    "    \n",
    "    bin_edges = np.arange(start=xmin, # The interval includes this value\n",
    "                     stop=xmax+step_size, # The interval doesn't include this value\n",
    "                     step=step_size ) # Spacing between values\n",
    "    bin_centres = np.arange(start=xmin+step_size/2, # The interval includes this value\n",
    "                            stop=xmax+step_size/2, # The interval doesn't include this value\n",
    "                            step=step_size ) # Spacing between values\n",
    "\n",
    "    data_x,_ = np.histogram(data['myy'], \n",
    "                            bins=bin_edges ) # histogram the data\n",
    "    data_x_errors = np.sqrt( data_x ) # statistical error on the data\n",
    "\n",
    "    # data fit\n",
    "    polynomial_mod = PolynomialModel( 4 ) # 4th order polynomial\n",
    "    gaussian_mod = GaussianModel() # Gaussian\n",
    "    \n",
    "    # set initial guesses for the parameters of the polynomial model\n",
    "    # c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "    pars = polynomial_mod.guess(data_x, # data to use to guess parameter values\n",
    "                                x=bin_centres, c0=data_x.max(), c1=0,\n",
    "                                c2=0, c3=0, c4=0 )\n",
    "    \n",
    "    # set initial guesses for the parameters of the Gaussian model\n",
    "    pars += gaussian_mod.guess(data_x, # data to use to guess parameter values\n",
    "                               x=bin_centres, amplitude=100, \n",
    "                               center=125, sigma=2 )\n",
    "    \n",
    "    model = polynomial_mod + gaussian_mod # combined model\n",
    "    \n",
    "    # fit the model to the data\n",
    "    out = model.fit(data_x, # data to be fit\n",
    "                    pars, # guesses for the parameters\n",
    "                    x=bin_centres, weights=1/data_x_errors ) \n",
    "\n",
    "    # background part of fit\n",
    "    params_dict = out.params.valuesdict() # get the parameters from the fit to data\n",
    "    c0 = params_dict['c0'] # c0 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "    c1 = params_dict['c1'] # c1 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "    c2 = params_dict['c2'] # c2 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "    c3 = params_dict['c3'] # c3 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "    c4 = params_dict['c4'] # c4 of c0 + c1*x + c2*x^2 + c3*x^3 + c4*x^4\n",
    "    \n",
    "    # get the background only part of the fit to data\n",
    "    background = c0 + c1*bin_centres + c2*bin_centres**2 + c3*bin_centres**3 + c4*bin_centres**4\n",
    "\n",
    "    # data fit - background fit = signal fit\n",
    "    signal_x = data_x - background \n",
    "\n",
    "\n",
    "    # *************\n",
    "    # Main plot \n",
    "    # *************\n",
    "    plt.axes([0.1,0.3,0.85,0.65]) # left, bottom, width, height \n",
    "    main_axes = plt.gca() # get current axes\n",
    "    \n",
    "    # plot the data points\n",
    "    main_axes.errorbar(x=bin_centres, y=data_x, yerr=data_x_errors, \n",
    "                       fmt='ko', # 'k' means black and 'o' means circles\n",
    "                       label='Data' ) \n",
    "    \n",
    "    # plot the signal + background fit\n",
    "    main_axes.plot(bin_centres, # x\n",
    "                   out.best_fit, # y\n",
    "                   '-r', # single red line\n",
    "                   label='Sig+Bkg Fit ($m_H=125$ GeV)' )\n",
    "    \n",
    "    # plot the background only fit\n",
    "    main_axes.plot(bin_centres, # x\n",
    "                   background, # y\n",
    "                   '--r', # dashed red line\n",
    "                   label='Bkg (4th order polynomial)' )\n",
    "\n",
    "    # set the x-limit of the main axes\n",
    "    main_axes.set_xlim( left=xmin, right=xmax ) \n",
    "    \n",
    "    # separation of x-axis minor ticks\n",
    "    main_axes.xaxis.set_minor_locator( AutoMinorLocator() ) \n",
    "    \n",
    "    # set the axis tick parameters for the main axes\n",
    "    main_axes.tick_params(which='both', # ticks on both x and y axes\n",
    "                          direction='in', # Put ticks inside and outside the axes\n",
    "                          top=True, # draw ticks on the top axis\n",
    "                          labelbottom=False, # don't draw tick labels on bottom axis\n",
    "                          right=True ) # draw ticks on right axis\n",
    "    \n",
    "    # write y-axis label for main axes\n",
    "    main_axes.set_ylabel('Events / '+str(step_size)+' GeV', \n",
    "                         horizontalalignment='right') \n",
    "    \n",
    "    # set the y-axis limit for the main axes\n",
    "    main_axes.set_ylim( bottom=0, top=np.amax(data_x)*1.1 ) \n",
    "    \n",
    "    # set minor ticks on the y-axis of the main axes\n",
    "    main_axes.yaxis.set_minor_locator( AutoMinorLocator() ) \n",
    "    \n",
    "    # avoid displaying y=0 on the main axes\n",
    "    main_axes.yaxis.get_major_ticks()[0].set_visible(False) \n",
    "\n",
    "    # Add text 'ATLAS Open Data' on plot\n",
    "    plt.text(0.2, # x\n",
    "             0.92, # y\n",
    "             'ATLAS Open Data', # text\n",
    "             transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "             fontsize=13 ) \n",
    "    \n",
    "    # Add text 'for education' on plot\n",
    "    plt.text(0.2, # x\n",
    "             0.86, # y\n",
    "             'for education', # text\n",
    "             transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "             style='italic',\n",
    "             fontsize=8 ) \n",
    "    \n",
    "    # Add energy and luminosity\n",
    "    lumi_used = str(lumi*fraction) # luminosity to write on the plot\n",
    "    plt.text(0.2, # x\n",
    "             0.8, # y\n",
    "             r'$\\sqrt{s}$=13 TeV,$\\int$L dt = '+lumi_used+r' fb$^{-1}$', # text\n",
    "             transform=main_axes.transAxes ) # coordinate system used is that of main_axes \n",
    "    \n",
    "    # Add a label for the analysis carried out\n",
    "    plt.text(0.2, # x\n",
    "             0.74, # y\n",
    "             r'$H \\rightarrow \\gamma\\gamma$', # text \n",
    "             transform=main_axes.transAxes ) # coordinate system used is that of main_axes\n",
    "\n",
    "    # draw the legend\n",
    "    main_axes.legend(frameon=False, # no box around the legend\n",
    "                     loc='lower left' ) # legend location \n",
    "\n",
    "\n",
    "    # *************\n",
    "    # Data-Bkg plot \n",
    "    # *************\n",
    "    plt.axes([0.1,0.1,0.85,0.2]) # left, bottom, width, height\n",
    "    sub_axes = plt.gca() # get the current axes\n",
    "    \n",
    "    # set the y axis to be symmetric about Data-Background=0\n",
    "    sub_axes.yaxis.set_major_locator( MaxNLocator(nbins='auto', \n",
    "                                                  symmetric=True) )\n",
    "    \n",
    "    # plot Data-Background\n",
    "    sub_axes.errorbar(x=bin_centres, y=signal_x, yerr=data_x_errors,\n",
    "                      fmt='ko' ) # 'k' means black and 'o' means circles\n",
    "    \n",
    "    # draw the fit to data\n",
    "    sub_axes.plot(bin_centres, # x\n",
    "                  out.best_fit-background, # y\n",
    "                  '-r' ) # single red line\n",
    "    \n",
    "    # draw the background only fit\n",
    "    sub_axes.plot(bin_centres, # x\n",
    "                  background-background, # y\n",
    "                  '--r' )  # dashed red line\n",
    "    \n",
    "    # set the x-axis limits on the sub axes\n",
    "    sub_axes.set_xlim( left=xmin, right=xmax ) \n",
    "    \n",
    "    # separation of x-axis minor ticks\n",
    "    sub_axes.xaxis.set_minor_locator( AutoMinorLocator() ) \n",
    "    \n",
    "    # x-axis label\n",
    "    sub_axes.set_xlabel(r'di-photon invariant mass $\\mathrm{m_{\\gamma\\gamma}}$ [GeV]',\n",
    "                        x=1, horizontalalignment='right', \n",
    "                        fontsize=13 ) \n",
    "    \n",
    "    # set the tick parameters for the sub axes\n",
    "    sub_axes.tick_params(which='both', # ticks on both x and y axes\n",
    "                         direction='in', # Put ticks inside and outside the axes\n",
    "                         top=True, # draw ticks on the top axis\n",
    "                         right=True ) # draw ticks on right axis \n",
    "    \n",
    "    # separation of y-axis minor ticks\n",
    "    sub_axes.yaxis.set_minor_locator( AutoMinorLocator() ) \n",
    "    \n",
    "    # y-axis label on the sub axes\n",
    "    sub_axes.set_ylabel( 'Events-Bkg' ) \n",
    "\n",
    "\n",
    "    # Generic features for both plots\n",
    "    main_axes.yaxis.set_label_coords( -0.09, 1 ) # x,y coordinates of the y-axis label on the main axes\n",
    "    sub_axes.yaxis.set_label_coords( -0.09, 0.5 ) # x,y coordinates of the y-axis label on the sub axes\n",
    "    \n",
    "    plt.savefig(\"correct_HyyAnalysis_graph.png\")\n",
    "    return bin_centres, out, background, params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_centres, out, background, params_dict = plot_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(params_dict)\n",
    "mean = params_dict[\"center\"]\n",
    "sigma = params_dict[\"sigma\"]\n",
    "one_std = (mean - sigma, mean+sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_len_2(series):\n",
    "    lens = series.apply(len)\n",
    "    mask = (lens == 2).to_numpy()\n",
    "    return series[mask]\n",
    "\n",
    "photon_pts = filter_len_2(data[\"photon_pt\"]).to_numpy()\n",
    "photon_etas = filter_len_2(data[\"photon_eta\"]).to_numpy()\n",
    "photon_phis = filter_len_2(data[\"photon_phi\"]).to_numpy()\n",
    "photon_Es = filter_len_2(data[\"photon_E\"]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(396373, 8)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "data_new = np.column_stack([photon_pts, photon_etas, photon_phis, photon_Es]).astype(np.float64)\n",
    "names = np.array(range(len(data_new)), dtype=np.float64)\n",
    "print(data_new.shape)\n",
    "print(type(data_new))\n",
    "print(type(data_new[0]))\n",
    "print(type(data_new[0][0]))\n",
    "np.savez(\"/gluster/home/ofrebato/baler/workspaces/higgs/data/13TeV_combined_cut_numpy.npz\", data=data_new, names=names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baler-O7HYjMIZ-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
